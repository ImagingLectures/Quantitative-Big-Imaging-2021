%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax

\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{times}
\expandafter\ifx\csname T@LGR\endcsname\relax
\else
% LGR was declared as font encoding
  \substitutefont{LGR}{\rmdefault}{cmr}
  \substitutefont{LGR}{\sfdefault}{cmss}
  \substitutefont{LGR}{\ttdefault}{cmtt}
\fi
\expandafter\ifx\csname T@X2\endcsname\relax
  \expandafter\ifx\csname T@T2A\endcsname\relax
  \else
  % T2A was declared as font encoding
    \substitutefont{T2A}{\rmdefault}{cmr}
    \substitutefont{T2A}{\sfdefault}{cmss}
    \substitutefont{T2A}{\ttdefault}{cmtt}
  \fi
\else
% X2 was declared as font encoding
  \substitutefont{X2}{\rmdefault}{cmr}
  \substitutefont{X2}{\sfdefault}{cmss}
  \substitutefont{X2}{\ttdefault}{cmtt}
\fi


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}




\title{Quantitative Big Imaging - Building and Augmenting Datasets}
\date{Mar 04, 2021}
\release{}
\author{Anders Kaestner}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{03-Datasets::doc}}


\sphinxAtStartPar
\sphinxstylestrong{Quantitative Big Imaging} ETHZ: 227\sphinxhyphen{}0966\sphinxhyphen{}00L




\chapter{Let’s load some modules for the notebook}
\label{\detokenize{03-Datasets:let-s-load-some-modules-for-the-notebook}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}    \PYG{k}{as} \PYG{n+nn}{mpl}
\PYG{k+kn}{import} \PYG{n+nn}{numpy}         \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{skimage}       \PYG{k}{as} \PYG{n+nn}{ski}
\PYG{k+kn}{import} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{io}    \PYG{k}{as} \PYG{n+nn}{io}
\PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{morphology} \PYG{k+kn}{import} \PYG{n}{disk}
\PYG{k+kn}{import} \PYG{n+nn}{scipy}\PYG{n+nn}{.}\PYG{n+nn}{ndimage} \PYG{k}{as} \PYG{n+nn}{ndimage}

\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{n}{mpl}\PYG{o}{.}\PYG{n}{rcParams}\PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{figure.dpi}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]} \PYG{o}{=} \PYG{l+m+mi}{300}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{o}{\PYGZlt{}}\PYG{n}{ipython}\PYG{o}{\PYGZhy{}}\PYG{n+nb}{input}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{o}{\PYGZhy{}}\PYG{n}{f8507326f08a}\PYG{o}{\PYGZgt{}} \PYG{o+ow}{in} \PYG{o}{\PYGZlt{}}\PYG{n}{module}\PYG{o}{\PYGZgt{}}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{2} \PYG{k+kn}{import} \PYG{n+nn}{matplotlib}    \PYG{k}{as} \PYG{n+nn}{mpl}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{3} \PYG{k+kn}{import} \PYG{n+nn}{numpy}         \PYG{k}{as} \PYG{n+nn}{np}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{4} \PYG{k+kn}{import} \PYG{n+nn}{skimage}       \PYG{k}{as} \PYG{n+nn}{ski}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{5} \PYG{k+kn}{import} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{io}    \PYG{k}{as} \PYG{n+nn}{io}
\PYG{g+gWhitespace}{      }\PYG{l+m+mi}{6} \PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{morphology} \PYG{k+kn}{import} \PYG{n}{disk}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}skimage\PYGZsq{}
\end{sphinxVerbatim}


\chapter{Today’s lecture}
\label{\detokenize{03-Datasets:today-s-lecture}}
\sphinxAtStartPar
\sphinxstylestrong{Creating Datasets}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Famous Datasets

\item {} 
\sphinxAtStartPar
Types of Datasets

\item {} 
\sphinxAtStartPar
What makes a good dataet?

\item {} 
\sphinxAtStartPar
Building your own

\item {} 
\sphinxAtStartPar
“scrape, mine, move, annotate, review, and preprocess” \sphinxhyphen{} Kathy Scott

\item {} 
\sphinxAtStartPar
tools to use

\item {} 
\sphinxAtStartPar
simulation

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Augmentation}
\begin{itemize}
\item {} 
\sphinxAtStartPar
How can you artifically increase the size of your dataset?

\item {} 
\sphinxAtStartPar
What are the limits of these increases

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Baselines}
\begin{itemize}
\item {} 
\sphinxAtStartPar
What is a baseline?

\item {} 
\sphinxAtStartPar
Example: Nearest Neighbor

\end{itemize}


\chapter{References}
\label{\detokenize{03-Datasets:references}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Revisiting \sphinxstylestrong{Unreasonable Effectiveness of Data} in Deep Learning Era: \sphinxurl{https://arxiv.org/abs/1707.02968}

\item {} 
\sphinxAtStartPar
Building Datasets
\begin{itemize}
\item {} 
\sphinxAtStartPar
Python Machine Learning 2nd Edition by Sebastian Raschka, Packt Publishing Ltd. 2017

\item {} 
\sphinxAtStartPar
Chapter 2: Building Good Datasets: \sphinxurl{https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch04/ch04.ipynb}

\item {} 
\sphinxAtStartPar
A Standardised Approach for Preparing Imaging Data for Machine Learning Tasks in Radiology \sphinxurl{https://doi.org/10.1007/978-3-319-94878-2\_6}

\end{itemize}

\item {} 
\sphinxAtStartPar
Creating Datasets / Crowdsourcing

\item {} 
\sphinxAtStartPar
Mindcontrol: A web application for brain segmentation quality control: \sphinxurl{https://www.sciencedirect.com/science/article/pii/S1053811917302707}

\item {} 
\sphinxAtStartPar
Combining citizen science and deep learning to amplify expertise in neuroimaging: \sphinxurl{https://www.biorxiv.org/content/10.1101/363382v1.abstract}

\item {} 
\sphinxAtStartPar
Augmentation

\item {} 
\sphinxAtStartPar
\sphinxurl{https://github.com/aleju/imgaug}

\item {} 
\sphinxAtStartPar
\sphinxurl{https://github.com/mdbloice/Augmentor}

\end{itemize}


\chapter{Motivation}
\label{\detokenize{03-Datasets:motivation}}
\sphinxAtStartPar
Most of you taking this class are rightfully excited to learn about new tools and algorithms to analyzing \sphinxstyleemphasis{your} data.

\sphinxAtStartPar
This lecture is a bit of an anomaly and perhaps disappointment because it doesn’t cover any algorithms, or tools.
\begin{itemize}
\item {} 
\sphinxAtStartPar
So you might ask, why are we spending so much time on datasets?

\item {} 
\sphinxAtStartPar
You already collected data (sometimes lots of it) that is why you took this class?!

\end{itemize}

\sphinxAtStartPar
… let’s see what some other people say


\section{Sean Taylor (Research Scientist at Facebook)}
\label{\detokenize{03-Datasets:sean-taylor-research-scientist-at-facebook}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.5]{{data_tweet}.jpg}
\caption{Realistic thoughts about AI.}\label{\detokenize{03-Datasets:id5}}\end{figure}




\section{Andrej Karpathy (Director of AI at Tesla)}
\label{\detokenize{03-Datasets:andrej-karpathy-director-of-ai-at-tesla}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{karpathy_slide}.jpg}
\caption{Time spent on different tasks.}\label{\detokenize{03-Datasets:id6}}\end{figure}




\section{Kathy Scott (Image Analytics Lead at Planet Labs)}
\label{\detokenize{03-Datasets:kathy-scott-image-analytics-lead-at-planet-labs}}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics[scale=0.7]{{kathy_tweet}.png}
\caption{The importance to spend sufficient time on data preparation.}\label{\detokenize{03-Datasets:id7}}\end{figure}




\section{Data is important}
\label{\detokenize{03-Datasets:data-is-important}}
\sphinxAtStartPar
It probably \sphinxhref{https://www.forbes.com/sites/bernardmarr/2018/03/05/heres-why-data-is-not-the-new-oil/}{isn’t the \sphinxstyleemphasis{new} oil}, but it forms an essential component for building modern tools today.
\begin{itemize}
\item {} 
\sphinxAtStartPar
Testing good algorithms \sphinxstyleemphasis{requires} good data

\item {} 
\sphinxAtStartPar
If you don’t know what to expect how do you know your algorithm worked?

\item {} 
\sphinxAtStartPar
If you have dozens of edge cases how can you make sure it works on each one?

\item {} 
\sphinxAtStartPar
If a new algorithm is developed every few hours, how can you be confident they actually work better (facebook’s site has a new version multiple times per day and their app every other day)

\item {} 
\sphinxAtStartPar
For machine learning, even building requires good data

\item {} 
\sphinxAtStartPar
If you count cells maybe you can write your own algorithm,

\item {} 
\sphinxAtStartPar
but if you are trying to detect subtle changes in cell structure that indicate cancer you probably can’t write a list of simple mathematical rules yourself.

\end{itemize}


\section{Data is reusable}
\label{\detokenize{03-Datasets:data-is-reusable}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Well organized and structured data is very easy to reuse.

\item {} 
\sphinxAtStartPar
Another project can easily combine your data with their data in order to get even better results.

\item {} 
\sphinxAtStartPar
Algorithms are often messy, complicated, poorly written, … (especially so if written by students trying to graduate on time)

\end{itemize}






\section{Data recycling saves time and improves performance}
\label{\detokenize{03-Datasets:data-recycling-saves-time-and-improves-performance}}





\chapter{Famous Datasets}
\label{\detokenize{03-Datasets:famous-datasets}}
\sphinxAtStartPar
The primary success of datasets has been shown through the most famous datasets collected.

\sphinxAtStartPar
Here I show
\begin{itemize}
\item {} 
\sphinxAtStartPar
Two of the most famous general datasets
\begin{itemize}
\item {} 
\sphinxAtStartPar
MNIST Digits

\item {} 
\sphinxAtStartPar
ImageNET

\end{itemize}

\item {} 
\sphinxAtStartPar
and one of the most famous medical datasets.
\begin{itemize}
\item {} 
\sphinxAtStartPar
BRATS

\end{itemize}

\end{itemize}

\sphinxAtStartPar
The famous datasets are important for basic network training.


\section{MNIST Digits}
\label{\detokenize{03-Datasets:mnist-digits}}
\sphinxAtStartPar
Modified NIST (National Institute of Standards and Technology) created a list of handwritten digits

\sphinxAtStartPar
\sphinxincludegraphics{{mnist}.png}


\section{ImageNet}
\label{\detokenize{03-Datasets:imagenet}}\begin{itemize}
\item {} 
\sphinxAtStartPar
ImageNet is an image database
\begin{itemize}
\item {} 
\sphinxAtStartPar
organized according to the WordNet hierarchy (currently only the nouns),

\item {} 
\sphinxAtStartPar
each node of the hierarchy is depicted by hundreds and thousands of images.

\end{itemize}

\item {} 
\sphinxAtStartPar
1000 different categories and \textgreater{}1M images.

\item {} 
\sphinxAtStartPar
Not just dog/cat, but wolf vs german shepard,

\end{itemize}



\sphinxAtStartPar
\sphinxhref{https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5}{CNN architectures}




\section{BRATS}
\label{\detokenize{03-Datasets:brats}}
\sphinxAtStartPar
Segmenting Tumors in Multimodal MRI Brain Images.




\section{What story did these datasets tell?}
\label{\detokenize{03-Datasets:what-story-did-these-datasets-tell}}
\sphinxAtStartPar
Each of these datasets is very different from images with fewer than 1000 pixels to images with more than 100MPx, but what they have in common is how their analysis has changed.


\subsection{Hand\sphinxhyphen{}crafted features}
\label{\detokenize{03-Datasets:hand-crafted-features}}
\sphinxAtStartPar
All of these datasets used to be analyzed by domain experts with hand\sphinxhyphen{}crafted features.
\begin{itemize}
\item {} 
\sphinxAtStartPar
A handwriting expert using graph topology to assign images to digits

\item {} 
\sphinxAtStartPar
A computer vision expert using gradients common in faces to identify people in ImageNet

\item {} 
\sphinxAtStartPar
A biomedical engineer using knowledge of different modalities to fuse them together and cluster healthy and tumorous tissue

\end{itemize}


\subsection{Machine Learning / Deep Learning}
\label{\detokenize{03-Datasets:machine-learning-deep-learning}}
\sphinxAtStartPar
Starting in the early 2010s, the approaches of deep learning began to improve and become more computationally efficient. With these techniques groups with \sphinxstylestrong{absolutely no domain knowledge} could begin building algorithms and winning contests based on these datasets


\section{So Deep Learning always wins?}
\label{\detokenize{03-Datasets:so-deep-learning-always-wins}}
\sphinxAtStartPar
No, that isn’t the point of this lecture.

\sphinxAtStartPar
Even if you aren’t using deep learning the point of these stories is having
\begin{itemize}
\item {} 
\sphinxAtStartPar
well\sphinxhyphen{}labeled,

\item {} 
\sphinxAtStartPar
structured,

\item {} 
\sphinxAtStartPar
and organized datasets

\end{itemize}

\sphinxAtStartPar
makes your problem \sphinxstyleemphasis{a lot more accessible} for other groups and enables a variety of different approaches to be tried.

\sphinxAtStartPar
Ultimately it enables better solutions to be made and you to be confident that the solutions are in fact better


\section{Other Datasets}
\label{\detokenize{03-Datasets:other-datasets}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{http://Grand-Challenge.org}{Grand\sphinxhyphen{}Challenge.org} a large number of challenges in the biomedical area

\item {} 
\sphinxAtStartPar
\sphinxhref{https://www.kaggle.com/datasets}{Kaggle Datasets}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://datasetsearch.research.google.com/}{Google Dataset Search}

\end{itemize}


\section{What makes a good dataset?}
\label{\detokenize{03-Datasets:what-makes-a-good-dataset}}

\subsection{Lots of images}
\label{\detokenize{03-Datasets:lots-of-images}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Small datasets can be useful but here the bigger the better

\item {} 
\sphinxAtStartPar
Particularly if you have
\begin{itemize}
\item {} 
\sphinxAtStartPar
Complicated problems

\item {} 
\sphinxAtStartPar
Very subtle differences (ie a lung tumor looks mostly like normal lung tissue but it is in a place it shouldn’t be)

\item {} 
\sphinxAtStartPar
Class imbalance

\end{itemize}

\end{itemize}


\section{What makes a good dataset?}
\label{\detokenize{03-Datasets:id1}}

\subsection{Lots of diversity}
\label{\detokenize{03-Datasets:lots-of-diversity}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Is it what data ‘in the wild’ really looks like?

\item {} 
\sphinxAtStartPar
Lots of different
\begin{itemize}
\item {} 
\sphinxAtStartPar
Scanners/reconstruction algorithms,

\item {} 
\sphinxAtStartPar
noise levels,

\item {} 
\sphinxAtStartPar
illumination types,

\item {} 
\sphinxAtStartPar
rotation,

\item {} 
\sphinxAtStartPar
colors, …

\end{itemize}

\item {} 
\sphinxAtStartPar
Many examples from different categories
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{if you only have one male with breast cancer it will be hard to generalize exactly what that looks like}

\end{itemize}

\end{itemize}


\section{What makes a good dataset?}
\label{\detokenize{03-Datasets:id2}}

\subsection{Meaningful labels}
\label{\detokenize{03-Datasets:meaningful-labels}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Clear task or question

\item {} 
\sphinxAtStartPar
Unambiguous (would multiple different labelers come to the same conclusion)

\item {} 
\sphinxAtStartPar
Able to be derived from the image alone
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{A label that someone cannot afford insurance is interesting but it would be nearly impossible to determine that from an X\sphinxhyphen{}ray of their lungs}

\end{itemize}

\item {} 
\sphinxAtStartPar
Quantiative!

\item {} 
\sphinxAtStartPar
Non\sphinxhyphen{}obvious
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{A label saying an image is bright is not a helpful label because you could look at the histogram and say that}

\end{itemize}

\end{itemize}


\chapter{Purpose of different types of Datasets}
\label{\detokenize{03-Datasets:purpose-of-different-types-of-datasets}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Classification

\item {} 
\sphinxAtStartPar
Regression

\item {} 
\sphinxAtStartPar
Segmentation

\item {} 
\sphinxAtStartPar
Detection

\item {} 
\sphinxAtStartPar
Other

\end{itemize}


\section{Classification}
\label{\detokenize{03-Datasets:classification}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Taking an image and putting it into a category

\item {} 
\sphinxAtStartPar
Each image should have exactly one category

\item {} 
\sphinxAtStartPar
The categories should be non\sphinxhyphen{}ordered

\item {} 
\sphinxAtStartPar
Example:

\item {} 
\sphinxAtStartPar
Cat vs Dog

\item {} 
\sphinxAtStartPar
Cancer vs Healthy

\end{itemize}


\subsection{Classification example}
\label{\detokenize{03-Datasets:classification-example}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{util} \PYG{k+kn}{import} \PYG{n}{montage} \PYG{k}{as} \PYG{n}{montage2d}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{9}\PYG{p}{,} \PYG{l+m+mi}{9}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{c\PYGZus{}ax}\PYG{p}{,} \PYG{n}{c\PYGZus{}img}\PYG{p}{,} \PYG{n}{c\PYGZus{}label} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{c\PYGZus{}img}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{n}{c\PYGZus{}label}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_30_0}.png}


\section{Regression}
\label{\detokenize{03-Datasets:regression}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Taking an image and predicting one (or more) decimal values

\item {} 
\sphinxAtStartPar
Examples:

\item {} 
\sphinxAtStartPar
Value of a house from the picture taken by owner

\item {} 
\sphinxAtStartPar
Risk of hurricane from satellite image

\end{itemize}


\subsection{Regression example Age from X\sphinxhyphen{}Rays}
\label{\detokenize{03-Datasets:regression-example-age-from-x-rays}}


\sphinxAtStartPar
\sphinxhref{https://www.kaggle.com/kmader/attention-on-pretrained-vgg16-for-bone-age}{More details}


\section{Segmentation}
\label{\detokenize{03-Datasets:segmentation}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Taking an image and predicting one (or more) values for each pixel

\item {} 
\sphinxAtStartPar
Every pixel needs a label (and a pixel cannot have multiple labels)

\item {} 
\sphinxAtStartPar
Typically limited to a few (\textless{}20) different types of objects

\item {} 
\sphinxAtStartPar
Examples:

\item {} 
\sphinxAtStartPar
Where a tumor is from an image of the lungs

\item {} 
\sphinxAtStartPar
Where streets are from satellite images of a neighborhood

\end{itemize}


\subsection{Segmentation example: Nuclei in Microscope Images}
\label{\detokenize{03-Datasets:segmentation-example-nuclei-in-microscope-images}}


\sphinxAtStartPar
\sphinxhref{https://www.kaggle.com/c/data-science-bowl-2018}{More details on Kaggle}


\section{Detection}
\label{\detokenize{03-Datasets:detection}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Taking an image and predicting where and which type of objects appear

\item {} 
\sphinxAtStartPar
Generally bounding box rather then specific pixels

\item {} 
\sphinxAtStartPar
Multiple objects can overlap

\end{itemize}


\subsection{Detection example: Opaque Regions in X\sphinxhyphen{}Rays}
\label{\detokenize{03-Datasets:detection-example-opaque-regions-in-x-rays}}
\sphinxAtStartPar
\sphinxincludegraphics{{lung_opacity}.png}

\sphinxAtStartPar
\sphinxhref{https://www.kaggle.com/c/rsna-pneumonia-detection-challenge}{More details on Kaggle}


\section{Other}
\label{\detokenize{03-Datasets:other}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Unlimited possibilities \sphinxhref{https://junyanz.github.io/CycleGAN/}{here}

\item {} 
\sphinxAtStartPar
Horses to Zebras

\end{itemize}


\subsection{Image Enhancement}
\label{\detokenize{03-Datasets:image-enhancement}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Denoising \sphinxhref{http://cchen156.web.engr.illinois.edu/SID.html}{Learning to See in the Dark}

\item {} 
\sphinxAtStartPar
\sphinxhref{https://data.vision.ee.ethz.ch/cvl/DIV2K/}{Super\sphinxhyphen{}resolution}

\end{itemize}


\chapter{Building your own data sets}
\label{\detokenize{03-Datasets:building-your-own-data-sets}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Very time consuming

\item {} 
\sphinxAtStartPar
Not a lot of great tools

\item {} 
\sphinxAtStartPar
Very problem specific

\end{itemize}


\section{Code\sphinxhyphen{}free}
\label{\detokenize{03-Datasets:code-free}}

\subsection{Classification}
\label{\detokenize{03-Datasets:id3}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Organize images into folders

\end{itemize}


\subsection{Regression}
\label{\detokenize{03-Datasets:id4}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Create an excel file (first column image name, next columns to regress)

\end{itemize}


\subsection{Segmentation / Object Detection}
\label{\detokenize{03-Datasets:segmentation-object-detection}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Take \sphinxhref{http://fiji.sc/}{FIJI} and manually draw region to be identified and save it as a grayscale image

\end{itemize}


\section{Software for data labelling}
\label{\detokenize{03-Datasets:software-for-data-labelling}}

\subsection{Free tools}
\label{\detokenize{03-Datasets:free-tools}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Classification / Segmentation: \sphinxurl{https://github.com/Labelbox/Labelbox}

\item {} 
\sphinxAtStartPar
Classification/ Object Detection: \sphinxurl{http://labelme.csail.mit.edu/Release3.0/}

\item {} 
\sphinxAtStartPar
Classification: \sphinxurl{https://github.com/janfreyberg/superintendent:} \sphinxurl{https://www.youtube.com/watch?v=fMg0mPYiEx0}

\item {} 
\sphinxAtStartPar
Classification/ Detection: \sphinxurl{https://github.com/chestrays/jupyanno:} \sphinxurl{https://www.youtube.com/watch?v=XDIJU5Beg\_w}

\item {} 
\sphinxAtStartPar
Classification (Tinder for Brain MRI): \sphinxurl{https://braindr.us/\#/}

\end{itemize}


\subsection{Commercial Approaches}
\label{\detokenize{03-Datasets:commercial-approaches}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxurl{https://www.figure-eight.com/}

\item {} 
\sphinxAtStartPar
MightyAI / Spare5: \sphinxurl{https://mighty.ai/} \sphinxurl{https://app.spare5.com/fives/sign\_in}

\end{itemize}


\section{Simulations}
\label{\detokenize{03-Datasets:simulations}}
\sphinxAtStartPar
Another way to enhance or expand your dataset is to use simulations
\begin{itemize}
\item {} 
\sphinxAtStartPar
already incorporate realistic data (game engines, 3D rendering, physics models)

\item {} 
\sphinxAtStartPar
100\% accurate ground truth (original models)

\item {} 
\sphinxAtStartPar
unlimited, risk\sphinxhyphen{}free playability (driving cars in the world is more dangerous)

\end{itemize}


\subsection{Examples}
\label{\detokenize{03-Datasets:examples}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://pdfs.semanticscholar.org/30a1/ba9142b9c3b755da2bff7d93d704494fdaed.pdf}{P. Fuchs et al. \sphinxhyphen{} Generating Meaningful Synthetic Ground Truth for
Pore Detection in Cast Aluminum Parts, iCT 2019, Padova}

\item {} 
\sphinxAtStartPar
\sphinxurl{https://download.visinf.tu-darmstadt.de/data/from\_games/}

\item {} 
\sphinxAtStartPar
\sphinxurl{https://pythonprogramming.net/self-driving-car-neural-network-training-data-python-plays-gta-v/}

\item {} 
\sphinxAtStartPar
\sphinxurl{https://towardsdatascience.com/learning-from-simulated-data-ff4be63ac89c}

\end{itemize}


\chapter{Dataset Problems}
\label{\detokenize{03-Datasets:dataset-problems}}
\sphinxAtStartPar
Some of the issues which can come up with datasets are
\begin{itemize}
\item {} 
\sphinxAtStartPar
imbalance

\item {} 
\sphinxAtStartPar
too few examples

\item {} 
\sphinxAtStartPar
too homogenous

\item {} 
\sphinxAtStartPar
and other possible problems

\end{itemize}

\sphinxAtStartPar
These lead to problems with the algorithms built on top of them.


\section{Bias}
\label{\detokenize{03-Datasets:bias}}
\sphinxAtStartPar
\sphinxincludegraphics{{google-racist-gorilla-doctored-tweet}.png}




\subsection{The solution was to remove Gorilla from the category}
\label{\detokenize{03-Datasets:the-solution-was-to-remove-gorilla-from-the-category}}



\section{Better solution would be to have training sets with more diverse people}
\label{\detokenize{03-Datasets:better-solution-would-be-to-have-training-sets-with-more-diverse-people}}

\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxhref{https://www.research.ibm.com/artificial-intelligence/trusted-ai/diversity-in-faces/}{IBM Diverse Face Dataset}

\end{itemize}


\chapter{Example of image data and labels}
\label{\detokenize{03-Datasets:example-of-image-data-and-labels}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{util} \PYG{k+kn}{import} \PYG{n}{montage} \PYG{k}{as} \PYG{n}{montage2d}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}

\PYG{n}{fig}\PYG{p}{,} \PYG{p}{(}\PYG{n}{ax1}\PYG{p}{,} \PYG{n}{ax2}\PYG{p}{)} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{8}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{d\PYGZus{}subset} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{where}\PYG{p}{(}\PYG{n}{np}\PYG{o}{.}\PYG{n}{in1d}\PYG{p}{(}\PYG{n}{label}\PYG{p}{,} \PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}
\PYG{n}{ax1}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{montage2d}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{d\PYGZus{}subset}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{64}\PYG{p}{]}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ax1}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Images}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ax1}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{ax2}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{d\PYGZus{}subset}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{64}\PYG{p}{]}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax2}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Digit Distribution}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_46_0}.png}


\chapter{Augmentation}
\label{\detokenize{03-Datasets:augmentation}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Most groups have too little well\sphinxhyphen{}labeled data and labeling new examples can be very expensive.

\item {} 
\sphinxAtStartPar
Additionally there might not be very many cases of specific classes.

\item {} 
\sphinxAtStartPar
In medicine this is particularly problematic, because some diseases might only happen a few times in a given hospital and you still want to be able to recognize the disease and not that particular person.

\end{itemize}


\section{Handling limited data}
\label{\detokenize{03-Datasets:handling-limited-data}}

\subsection{Transformations}
\label{\detokenize{03-Datasets:transformations}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Shift

\item {} 
\sphinxAtStartPar
Zoom

\item {} 
\sphinxAtStartPar
Rotation

\item {} 
\sphinxAtStartPar
Intensity

\item {} 
\sphinxAtStartPar
Normalization

\item {} 
\sphinxAtStartPar
Scaling

\item {} 
\sphinxAtStartPar
Color

\item {} 
\sphinxAtStartPar
Shear

\end{itemize}


\subsection{Further modifications}
\label{\detokenize{03-Datasets:further-modifications}}\begin{itemize}
\item {} 
\sphinxAtStartPar
Add noise

\item {} 
\sphinxAtStartPar
Blurring

\end{itemize}


\section{Some augmentation examples}
\label{\detokenize{03-Datasets:some-augmentation-examples}}


\sphinxAtStartPar
Retial images from \sphinxhref{https://drive.grand-challenge.org/DRIVE/}{DRIVE} prepared by Gian Guido Parenza.




\section{Limitations of augmentation}
\label{\detokenize{03-Datasets:limitations-of-augmentation}}\begin{itemize}
\item {} 
\sphinxAtStartPar
What transformations are normal in the images?

\item {} 
\sphinxAtStartPar
CT images usually do not get flipped (the head is always on the top)

\item {} 
\sphinxAtStartPar
The values in CT images have a physical meaning (Hounsfield unit),  \(\rightarrow\) scaling them changes the image

\item {} 
\sphinxAtStartPar
How much distortion is too much?

\item {} 
\sphinxAtStartPar
Can you still recognize the features?

\end{itemize}


\section{Keras ImageDataGenerator}
\label{\detokenize{03-Datasets:keras-imagedatagenerator}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
ImageDataGenerator(
    [\PYGZsq{}featurewise\PYGZus{}center=False\PYGZsq{}, \PYGZsq{}samplewise\PYGZus{}center=False\PYGZsq{}, \PYGZsq{}featurewise\PYGZus{}std\PYGZus{}normalization=False\PYGZsq{}, \PYGZsq{}samplewise\PYGZus{}std\PYGZus{}normalization=False\PYGZsq{}, \PYGZsq{}zca\PYGZus{}whitening=False\PYGZsq{}, \PYGZsq{}zca\PYGZus{}epsilon=1e\PYGZhy{}06\PYGZsq{}, \PYGZsq{}rotation\PYGZus{}range=0.0\PYGZsq{}, \PYGZsq{}width\PYGZus{}shift\PYGZus{}range=0.0\PYGZsq{}, \PYGZsq{}height\PYGZus{}shift\PYGZus{}range=0.0\PYGZsq{}, \PYGZsq{}shear\PYGZus{}range=0.0\PYGZsq{}, \PYGZsq{}zoom\PYGZus{}range=0.0\PYGZsq{}, \PYGZsq{}channel\PYGZus{}shift\PYGZus{}range=0.0\PYGZsq{}, \PYGZdq{}fill\PYGZus{}mode=\PYGZsq{}nearest\PYGZsq{}\PYGZdq{}, \PYGZsq{}cval=0.0\PYGZsq{}, \PYGZsq{}horizontal\PYGZus{}flip=False\PYGZsq{}, \PYGZsq{}vertical\PYGZus{}flip=False\PYGZsq{}, \PYGZsq{}rescale=None\PYGZsq{}, \PYGZsq{}preprocessing\PYGZus{}function=None\PYGZsq{}, \PYGZsq{}data\PYGZus{}format=None\PYGZsq{}],
)
Docstring:     
Generate minibatches of image data with real\PYGZhy{}time data augmentation.

\PYGZsh{} Arguments
    featurewise\PYGZus{}center: set input mean to 0 over the dataset.
    samplewise\PYGZus{}center: set each sample mean to 0.
    featurewise\PYGZus{}std\PYGZus{}normalization: divide inputs by std of the dataset.
    samplewise\PYGZus{}std\PYGZus{}normalization: divide each input by its std.
    zca\PYGZus{}whitening: apply ZCA whitening.
    zca\PYGZus{}epsilon: epsilon for ZCA whitening. Default is 1e\PYGZhy{}6.
    rotation\PYGZus{}range: degrees (0 to 180).
    width\PYGZus{}shift\PYGZus{}range: fraction of total width, if \PYGZlt{} 1, or pixels if \PYGZgt{}= 1.
    height\PYGZus{}shift\PYGZus{}range: fraction of total height, if \PYGZlt{} 1, or pixels if \PYGZgt{}= 1.
    shear\PYGZus{}range: shear intensity (shear angle in degrees).
    zoom\PYGZus{}range: amount of zoom. if scalar z, zoom will be randomly picked
        in the range [1\PYGZhy{}z, 1+z]. A sequence of two can be passed instead
        to select this range.
    channel\PYGZus{}shift\PYGZus{}range: shift range for each channel.
    fill\PYGZus{}mode: points outside the boundaries are filled according to the
        given mode (\PYGZsq{}constant\PYGZsq{}, \PYGZsq{}nearest\PYGZsq{}, \PYGZsq{}reflect\PYGZsq{} or \PYGZsq{}wrap\PYGZsq{}). Default
        is \PYGZsq{}nearest\PYGZsq{}.
        Points outside the boundaries of the input are filled according to the given mode:
            \PYGZsq{}constant\PYGZsq{}: kkkkkkkk|abcd|kkkkkkkk (cval=k)
            \PYGZsq{}nearest\PYGZsq{}:  aaaaaaaa|abcd|dddddddd
            \PYGZsq{}reflect\PYGZsq{}:  abcddcba|abcd|dcbaabcd
            \PYGZsq{}wrap\PYGZsq{}:  abcdabcd|abcd|abcdabcd
    cval: value used for points outside the boundaries when fill\PYGZus{}mode is
        \PYGZsq{}constant\PYGZsq{}. Default is 0.
    horizontal\PYGZus{}flip: whether to randomly flip images horizontally.
    vertical\PYGZus{}flip: whether to randomly flip images vertically.
    rescale: rescaling factor. If None or 0, no rescaling is applied,
        otherwise we multiply the data by the value provided. This is
        applied after the `preprocessing\PYGZus{}function` (if any provided)
        but before any other transformation.
    preprocessing\PYGZus{}function: function that will be implied on each input.
        The function will run before any other modification on it.
        The function should take one argument:
        one image (Numpy tensor with rank 3),
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{preprocessing}\PYG{n+nn}{.}\PYG{n+nn}{image} \PYG{k+kn}{import} \PYG{n}{ImageDataGenerator}
\PYG{n}{img\PYGZus{}aug} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}
    \PYG{n}{featurewise\PYGZus{}center}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{samplewise\PYGZus{}center}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{zca\PYGZus{}whitening}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{zca\PYGZus{}epsilon}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}06}\PYG{p}{,}
    \PYG{n}{rotation\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{30.0}\PYG{p}{,}
    \PYG{n}{width\PYGZus{}shift\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{height\PYGZus{}shift\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{shear\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{zoom\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.5}\PYG{p}{,}
    \PYG{n}{fill\PYGZus{}mode}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{nearest}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
    \PYG{n}{horizontal\PYGZus{}flip}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{vertical\PYGZus{}flip}\PYG{o}{=}\PYG{k+kc}{False}
\PYG{p}{)}
\end{sphinxVerbatim}


\section{MNIST}
\label{\detokenize{03-Datasets:mnist}}
\sphinxAtStartPar
Even something as simple as labeling digits can be very time consuming (maybe 1\sphinxhyphen{}2 per second).

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{img} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{expand\PYGZus{}dims}\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{14}\PYG{p}{,} \PYG{l+m+mi}{9}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} setup augmentation}
\PYG{n}{img\PYGZus{}aug}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}
\PYG{n}{real\PYGZus{}aug} \PYG{o}{=} \PYG{n}{img\PYGZus{}aug}\PYG{o}{.}\PYG{n}{flow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,} \PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{c\PYGZus{}axs}\PYG{p}{,} \PYG{n}{do\PYGZus{}augmentation} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{p}{,} \PYG{p}{[}\PYG{k+kc}{False}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{do\PYGZus{}augmentation}\PYG{p}{:}
        \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch} \PYG{o}{=} \PYG{n+nb}{next}\PYG{p}{(}\PYG{n}{real\PYGZus{}aug}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch} \PYG{o}{=} \PYG{n}{img}\PYG{p}{,} \PYG{n}{label}
    \PYG{k}{for} \PYG{n}{c\PYGZus{}ax}\PYG{p}{,} \PYG{n}{c\PYGZus{}img}\PYG{p}{,} \PYG{n}{c\PYGZus{}label} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{c\PYGZus{}axs}\PYG{p}{,} \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{c\PYGZus{}img}\PYG{p}{[}\PYG{p}{:}\PYG{p}{,} \PYG{p}{:}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{vmin}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{vmax}\PYG{o}{=}\PYG{l+m+mi}{255}\PYG{p}{)}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(} \PYG{n}{c\PYGZus{}label}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{aug}\PYG{l+s+s1}{\PYGZsq{}} \PYG{k}{if} \PYG{n}{do\PYGZus{}augmentation} \PYG{k}{else} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_55_0}.png}


\chapter{A larger open data set}
\label{\detokenize{03-Datasets:a-larger-open-data-set}}
\sphinxAtStartPar
\sphinxhref{https://www.cs.toronto.edu/~kriz/cifar.html}{CIFAR10}
We can use a more exciting dataset to try some of the other features in augmentation

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{cifar10}
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{cifar10}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{img\PYGZus{}aug} \PYG{o}{=} \PYG{n}{ImageDataGenerator}\PYG{p}{(}
    \PYG{n}{featurewise\PYGZus{}center}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{samplewise\PYGZus{}center}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{zca\PYGZus{}whitening}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{,}
    \PYG{n}{zca\PYGZus{}epsilon}\PYG{o}{=}\PYG{l+m+mf}{1e\PYGZhy{}06}\PYG{p}{,}
    \PYG{n}{rotation\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{30.0}\PYG{p}{,}
    \PYG{n}{width\PYGZus{}shift\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{height\PYGZus{}shift\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{channel\PYGZus{}shift\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{shear\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mf}{0.25}\PYG{p}{,}
    \PYG{n}{zoom\PYGZus{}range}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{,}
    \PYG{n}{fill\PYGZus{}mode}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{reflect}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,}
    \PYG{n}{horizontal\PYGZus{}flip}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,}
    \PYG{n}{vertical\PYGZus{}flip}\PYG{o}{=}\PYG{k+kc}{True}
\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{10}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{16}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} setup augmentation}
\PYG{n}{img\PYGZus{}aug}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{img}\PYG{p}{)}
\PYG{n}{real\PYGZus{}aug} \PYG{o}{=} \PYG{n}{img\PYGZus{}aug}\PYG{o}{.}\PYG{n}{flow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,} \PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{,} \PYG{n}{shuffle}\PYG{o}{=}\PYG{k+kc}{False}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{c\PYGZus{}axs}\PYG{p}{,} \PYG{n}{do\PYGZus{}augmentation} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{p}{,} \PYG{p}{[}\PYG{k+kc}{False}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{,} \PYG{k+kc}{True}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{k}{if} \PYG{n}{do\PYGZus{}augmentation}\PYG{p}{:}
        \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch} \PYG{o}{=} \PYG{n+nb}{next}\PYG{p}{(}\PYG{n}{real\PYGZus{}aug}\PYG{p}{)}
        \PYG{n}{img\PYGZus{}batch} \PYG{o}{\PYGZhy{}}\PYG{o}{=} \PYG{n}{img\PYGZus{}batch}\PYG{o}{.}\PYG{n}{min}\PYG{p}{(}\PYG{p}{)}
        \PYG{n}{img\PYGZus{}batch} \PYG{o}{=} \PYG{n}{np}\PYG{o}{.}\PYG{n}{clip}\PYG{p}{(}\PYG{n}{img\PYGZus{}batch}\PYG{o}{/}\PYG{n}{img\PYGZus{}batch}\PYG{o}{.}\PYG{n}{max}\PYG{p}{(}\PYG{p}{)} \PYG{o}{*}
                            \PYG{l+m+mi}{255}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{255}\PYG{p}{)}\PYG{o}{.}\PYG{n}{astype}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{uint8}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{k}{else}\PYG{p}{:}
        \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch} \PYG{o}{=} \PYG{n}{img}\PYG{p}{,} \PYG{n}{label}
    \PYG{k}{for} \PYG{n}{c\PYGZus{}ax}\PYG{p}{,} \PYG{n}{c\PYGZus{}img}\PYG{p}{,} \PYG{n}{c\PYGZus{}label} \PYG{o+ow}{in} \PYG{n+nb}{zip}\PYG{p}{(}\PYG{n}{c\PYGZus{}axs}\PYG{p}{,} \PYG{n}{img\PYGZus{}batch}\PYG{p}{,} \PYG{n}{label\PYGZus{}batch}\PYG{p}{)}\PYG{p}{:}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{c\PYGZus{}img}\PYG{p}{)}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}
            \PYG{n}{c\PYGZus{}label}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{aug}\PYG{l+s+s1}{\PYGZsq{}} \PYG{k}{if} \PYG{n}{do\PYGZus{}augmentation} \PYG{k}{else} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{)}
        \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_59_0}.png}


\chapter{Baselines}
\label{\detokenize{03-Datasets:baselines}}\begin{itemize}
\item {} 
\sphinxAtStartPar
A baseline is a simple, easily implemented and understood model that illustrates the problem and the ‘worst\sphinxhyphen{}case scenario’ for a model that learns nothing (some models will do worse, but these are especially useless).

\item {} 
\sphinxAtStartPar
Why is this important?

\end{itemize}


\section{Baseline model example}
\label{\detokenize{03-Datasets:baseline-model-example}}
\sphinxAtStartPar
I have a a model that is \textgreater{}99\% accurate for predicting breast cancer
\begin{equation*}
\begin{split} \textrm{DoIHaveBreastCancer}(\textrm{Age}, \textrm{Weight}, \textrm{Race}) = \textrm{No!} \end{split}
\end{equation*}



\section{The dummy classifier}
\label{\detokenize{03-Datasets:the-dummy-classifier}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{dummy} \PYG{k+kn}{import} \PYG{n}{DummyClassifier}
\PYG{n}{dc} \PYG{o}{=} \PYG{n}{DummyClassifier}\PYG{p}{(}\PYG{n}{strategy}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{most\PYGZus{}frequent}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{dc}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{2}\PYG{p}{,} \PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{,} 
       \PYG{p}{[}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Healthy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Healthy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Healthy}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Cancer}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
DummyClassifier(strategy=\PYGZsq{}most\PYGZus{}frequent\PYGZsq{})
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{3}\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} \PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{p}{[}\PYG{l+m+mi}{100}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
(array([\PYGZsq{}Healthy\PYGZsq{}], dtype=\PYGZsq{}\PYGZlt{}U7\PYGZsq{}),
 array([\PYGZsq{}Healthy\PYGZsq{}], dtype=\PYGZsq{}\PYGZlt{}U7\PYGZsq{}),
 array([\PYGZsq{}Healthy\PYGZsq{}], dtype=\PYGZsq{}\PYGZlt{}U7\PYGZsq{}),
 array([\PYGZsq{}Healthy\PYGZsq{}], dtype=\PYGZsq{}\PYGZlt{}U7\PYGZsq{}))
\end{sphinxVerbatim}


\section{Try dummy classifier on MNIST data}
\label{\detokenize{03-Datasets:try-dummy-classifier-on-mnist-data}}
\sphinxAtStartPar
First we load the data…

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{util} \PYG{k+kn}{import} \PYG{n}{montage} \PYG{k}{as} \PYG{n}{montage2d}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{m\PYGZus{}axs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{m\PYGZus{}axs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Digit Distribution}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{c\PYGZus{}ax} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{:}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_66_0}.png}


\section{Let’s train the model…}
\label{\detokenize{03-Datasets:let-s-train-the-model}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dc} \PYG{o}{=} \PYG{n}{DummyClassifier}\PYG{p}{(}\PYG{n}{strategy}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{most\PYGZus{}frequent}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{n}{dc}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{,} \PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
DummyClassifier(strategy=\PYGZsq{}most\PYGZus{}frequent\PYGZsq{})
\end{sphinxVerbatim}

\sphinxAtStartPar
\sphinxstylestrong{A basic test}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=uint8)
\end{sphinxVerbatim}


\subsection{… why are all predictions = 1?}
\label{\detokenize{03-Datasets:why-are-all-predictions-1}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{plt}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Frequency of numbers in the training data}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_72_0}.png}


\subsection{Test on the images}
\label{\detokenize{03-Datasets:test-on-the-images}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{c\PYGZus{}ax} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Predicted: }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{dc}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}  
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_74_0}.png}


\section{Nearest Neighbor}
\label{\detokenize{03-Datasets:nearest-neighbor}}
\sphinxAtStartPar
This isn’t a machine learning class and so we won’t dive deeply into other methods, but nearest neighbor is often a very good baseline (that is also very easy to understand). You basically take the element from the original set that is closest to the image you show.



\sphinxAtStartPar
\sphinxhref{https://www.crcpress.com/The-Image-Processing-Handbook/Russ-Neal/p/book/9781138747494}{Figure from J. Russ, Image Processing Handbook}

\sphinxAtStartPar
You can make the method more robust by using more than one nearest neighbor (hence K nearest neighbors), but that we will cover in the supervised methods lecture


\subsection{Let’s load the data again…}
\label{\detokenize{03-Datasets:let-s-load-the-data-again}}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{numpy} \PYG{k}{as} \PYG{n+nn}{np}
\PYG{k+kn}{import} \PYG{n+nn}{matplotlib}\PYG{n+nn}{.}\PYG{n+nn}{pyplot} \PYG{k}{as} \PYG{n+nn}{plt}
\PYG{k+kn}{from} \PYG{n+nn}{keras}\PYG{n+nn}{.}\PYG{n+nn}{datasets} \PYG{k+kn}{import} \PYG{n}{mnist}
\PYG{k+kn}{from} \PYG{n+nn}{skimage}\PYG{n+nn}{.}\PYG{n+nn}{util} \PYG{k+kn}{import} \PYG{n}{montage} \PYG{k}{as} \PYG{n}{montage2d}
\PYG{o}{\PYGZpc{}}\PYG{k}{matplotlib} inline
\PYG{p}{(}\PYG{n}{img}\PYG{p}{,} \PYG{n}{label}\PYG{p}{)}\PYG{p}{,} \PYG{n}{\PYGZus{}} \PYG{o}{=} \PYG{n}{mnist}\PYG{o}{.}\PYG{n}{load\PYGZus{}data}\PYG{p}{(}\PYG{p}{)}
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{5}\PYG{p}{,} \PYG{l+m+mi}{5}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{m\PYGZus{}axs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{hist}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{,} \PYG{n}{np}\PYG{o}{.}\PYG{n}{arange}\PYG{p}{(}\PYG{l+m+mi}{11}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{m\PYGZus{}axs}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{l+m+mi}{0}\PYG{p}{]}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Digit Distribution}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{c\PYGZus{}ax} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{:}\PYG{p}{]}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_77_0}.png}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{neighbors} \PYG{k+kn}{import} \PYG{n}{KNeighborsClassifier}
\PYG{n}{neigh\PYGZus{}class} \PYG{o}{=} \PYG{n}{KNeighborsClassifier}\PYG{p}{(}\PYG{n}{n\PYGZus{}neighbors}\PYG{o}{=}\PYG{l+m+mi}{1}\PYG{p}{)}
\PYG{n}{neigh\PYGZus{}class}\PYG{o}{.}\PYG{n}{fit}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{24}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} \PYG{n}{label}\PYG{p}{[}\PYG{p}{:}\PYG{l+m+mi}{24}\PYG{p}{]}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
KNeighborsClassifier(n\PYGZus{}neighbors=1)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} predict on a few images}
\PYG{n}{neigh\PYGZus{}class}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{:}\PYG{l+m+mi}{10}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{c\PYGZus{}ax} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Predicted: }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} 
                                              \PYG{n}{neigh\PYGZus{}class}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_80_0}.png}


\subsection{100\% for a baseline}
\label{\detokenize{03-Datasets:for-a-baseline}}
\sphinxAtStartPar
Wow the model works really really well, it got every example perfectly. What we did here (a common mistake) was evaluate on the same data we ‘trained’ on which means the model just correctly recalled each example, if we try it on new images we can see the performance drop but still a reasonable result

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{n}{fig}\PYG{p}{,} \PYG{n}{m\PYGZus{}axs} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{4}\PYG{p}{,} \PYG{l+m+mi}{6}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{p}{(}\PYG{l+m+mi}{12}\PYG{p}{,} \PYG{l+m+mi}{12}\PYG{p}{)}\PYG{p}{)}
\PYG{k}{for} \PYG{n}{i}\PYG{p}{,} \PYG{n}{c\PYGZus{}ax} \PYG{o+ow}{in} \PYG{n+nb}{enumerate}\PYG{p}{(}\PYG{n}{m\PYGZus{}axs}\PYG{o}{.}\PYG{n}{flatten}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{l+m+mi}{25}\PYG{p}{)}\PYG{p}{:}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{imshow}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} \PYG{n}{cmap}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{gray}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+se}{\PYGZbs{}n}\PYG{l+s+s1}{Predicted: }\PYG{l+s+si}{\PYGZob{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{p}{,} 
                                              \PYG{n}{neigh\PYGZus{}class}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{n}{i}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{[}\PYG{l+m+mi}{0}\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
    \PYG{n}{c\PYGZus{}ax}\PYG{o}{.}\PYG{n}{axis}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{off}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_82_0}.png}


\section{How good is good?}
\label{\detokenize{03-Datasets:how-good-is-good}}
\sphinxAtStartPar
We will cover more tools later in the class but now we will show the accuracy and the confusion matrix for our simple baseline model to evaluate how well it worked


\subsection{Confusion Matrix}
\label{\detokenize{03-Datasets:confusion-matrix}}
\sphinxAtStartPar
We show which cases were most frequently confused



\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{import} \PYG{n+nn}{seaborn} \PYG{k}{as} \PYG{n+nn}{sns}
\PYG{k+kn}{import} \PYG{n+nn}{pandas} \PYG{k}{as} \PYG{n+nn}{pd}
\PYG{k}{def} \PYG{n+nf}{print\PYGZus{}confusion\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{confusion\PYGZus{}matrix}\PYG{p}{,} \PYG{n}{class\PYGZus{}names}\PYG{p}{,} \PYG{n}{figsize} \PYG{o}{=} \PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{,}\PYG{l+m+mi}{7}\PYG{p}{)}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{l+m+mi}{14}\PYG{p}{)}\PYG{p}{:}
    \PYG{l+s+sd}{\PYGZdq{}\PYGZdq{}\PYGZdq{}Prints a confusion matrix, as returned by sklearn.metrics.confusion\PYGZus{}matrix, as a heatmap.}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    Stolen from: https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823}
\PYG{l+s+sd}{    }
\PYG{l+s+sd}{    Arguments}
\PYG{l+s+sd}{    \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{    confusion\PYGZus{}matrix: numpy.ndarray}
\PYG{l+s+sd}{        The numpy.ndarray object returned from a call to sklearn.metrics.confusion\PYGZus{}matrix. }
\PYG{l+s+sd}{        Similarly constructed ndarrays can also be used.}
\PYG{l+s+sd}{    class\PYGZus{}names: list}
\PYG{l+s+sd}{        An ordered list of class names, in the order they index the given confusion matrix.}
\PYG{l+s+sd}{    figsize: tuple}
\PYG{l+s+sd}{        A 2\PYGZhy{}long tuple, the first value determining the horizontal size of the ouputted figure,}
\PYG{l+s+sd}{        the second determining the vertical size. Defaults to (10,7).}
\PYG{l+s+sd}{    fontsize: int}
\PYG{l+s+sd}{        Font size for axes labels. Defaults to 14.}
\PYG{l+s+sd}{        }
\PYG{l+s+sd}{    Returns}
\PYG{l+s+sd}{    \PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{l+s+sd}{    matplotlib.figure.Figure}
\PYG{l+s+sd}{        The resulting confusion matrix figure}
\PYG{l+s+sd}{    \PYGZdq{}\PYGZdq{}\PYGZdq{}}
    \PYG{n}{df\PYGZus{}cm} \PYG{o}{=} \PYG{n}{pd}\PYG{o}{.}\PYG{n}{DataFrame}\PYG{p}{(}
        \PYG{n}{confusion\PYGZus{}matrix}\PYG{p}{,} \PYG{n}{index}\PYG{o}{=}\PYG{n}{class\PYGZus{}names}\PYG{p}{,} \PYG{n}{columns}\PYG{o}{=}\PYG{n}{class\PYGZus{}names}\PYG{p}{,} 
    \PYG{p}{)}
    \PYG{n}{fig}\PYG{p}{,} \PYG{n}{ax1} \PYG{o}{=} \PYG{n}{plt}\PYG{o}{.}\PYG{n}{subplots}\PYG{p}{(}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{1}\PYG{p}{,} \PYG{n}{figsize}\PYG{o}{=}\PYG{n}{figsize}\PYG{p}{)}
    \PYG{k}{try}\PYG{p}{:}
        \PYG{n}{heatmap} \PYG{o}{=} \PYG{n}{sns}\PYG{o}{.}\PYG{n}{heatmap}\PYG{p}{(}\PYG{n}{df\PYGZus{}cm}\PYG{p}{,} \PYG{n}{annot}\PYG{o}{=}\PYG{k+kc}{True}\PYG{p}{,} \PYG{n}{fmt}\PYG{o}{=}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{d}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{k}{except} \PYG{n+ne}{ValueError}\PYG{p}{:}
        \PYG{k}{raise} \PYG{n+ne}{ValueError}\PYG{p}{(}\PYG{l+s+s2}{\PYGZdq{}}\PYG{l+s+s2}{Confusion matrix values must be integers.}\PYG{l+s+s2}{\PYGZdq{}}\PYG{p}{)}
    \PYG{n}{heatmap}\PYG{o}{.}\PYG{n}{yaxis}\PYG{o}{.}\PYG{n}{set\PYGZus{}ticklabels}\PYG{p}{(}\PYG{n}{heatmap}\PYG{o}{.}\PYG{n}{yaxis}\PYG{o}{.}\PYG{n}{get\PYGZus{}ticklabels}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{rotation}\PYG{o}{=}\PYG{l+m+mi}{0}\PYG{p}{,} \PYG{n}{ha}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{right}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{n}{fontsize}\PYG{p}{)}
    \PYG{n}{heatmap}\PYG{o}{.}\PYG{n}{xaxis}\PYG{o}{.}\PYG{n}{set\PYGZus{}ticklabels}\PYG{p}{(}\PYG{n}{heatmap}\PYG{o}{.}\PYG{n}{xaxis}\PYG{o}{.}\PYG{n}{get\PYGZus{}ticklabels}\PYG{p}{(}\PYG{p}{)}\PYG{p}{,} \PYG{n}{rotation}\PYG{o}{=}\PYG{l+m+mi}{45}\PYG{p}{,} \PYG{n}{ha}\PYG{o}{=}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{right}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{,} \PYG{n}{fontsize}\PYG{o}{=}\PYG{n}{fontsize}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{ylabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{True label}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{n}{plt}\PYG{o}{.}\PYG{n}{xlabel}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Predicted label}\PYG{l+s+s1}{\PYGZsq{}}\PYG{p}{)}
    \PYG{k}{return} \PYG{n}{ax1}
\end{sphinxVerbatim}

\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{k+kn}{from} \PYG{n+nn}{sklearn}\PYG{n+nn}{.}\PYG{n+nn}{metrics} \PYG{k+kn}{import} \PYG{n}{accuracy\PYGZus{}score}\PYG{p}{,} \PYG{n}{confusion\PYGZus{}matrix}
\PYG{n}{pred\PYGZus{}values} \PYG{o}{=} \PYG{n}{neigh\PYGZus{}class}\PYG{o}{.}\PYG{n}{predict}\PYG{p}{(}\PYG{n}{img}\PYG{p}{[}\PYG{l+m+mi}{24}\PYG{p}{:}\PYG{p}{]}\PYG{o}{.}\PYG{n}{reshape}\PYG{p}{(}\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{l+m+mi}{1}\PYG{p}{,} \PYG{l+m+mi}{28}\PYG{o}{*}\PYG{l+m+mi}{28}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax1} \PYG{o}{=} \PYG{n}{print\PYGZus{}confusion\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{confusion\PYGZus{}matrix}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{l+m+mi}{24}\PYG{p}{:}\PYG{p}{]}\PYG{p}{,} \PYG{n}{pred\PYGZus{}values}\PYG{p}{)}\PYG{p}{,} \PYG{n}{class\PYGZus{}names}\PYG{o}{=}\PYG{n+nb}{range}\PYG{p}{(}\PYG{l+m+mi}{10}\PYG{p}{)}\PYG{p}{)}
\PYG{n}{ax1}\PYG{o}{.}\PYG{n}{set\PYGZus{}title}\PYG{p}{(}\PYG{l+s+s1}{\PYGZsq{}}\PYG{l+s+s1}{Accuracy: }\PYG{l+s+si}{\PYGZob{}:2.2\PYGZpc{}\PYGZcb{}}\PYG{l+s+s1}{\PYGZsq{}}\PYG{o}{.}\PYG{n}{format}\PYG{p}{(}\PYG{n}{accuracy\PYGZus{}score}\PYG{p}{(}\PYG{n}{label}\PYG{p}{[}\PYG{l+m+mi}{24}\PYG{p}{:}\PYG{p}{]}\PYG{p}{,} \PYG{n}{pred\PYGZus{}values}\PYG{p}{)}\PYG{p}{)}\PYG{p}{)}\PYG{p}{;}
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{03-Datasets_85_0}.png}


\chapter{Summary}
\label{\detokenize{03-Datasets:summary}}






\renewcommand{\indexname}{Index}
\printindex
\end{document}