{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An extension of 4\n",
    "Here we show how to build a basic neural network for identifying dog or muffin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "from IPython.display import display\n",
    "import numpy as np  # linear algebra / matrices\n",
    "from skimage.color import label2rgb\n",
    "from sklearn.metrics import roc_curve, auc  # roc curve tools\n",
    "from skimage.segmentation import mark_boundaries  # mark labels\n",
    "from skimage.io import imread  # read in images\n",
    "import matplotlib.pyplot as plt  # plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../04-Segmentation/04-files'\n",
    "seg_path = os.path.join(base_path, 'DogVsMuffin_seg_bw.jpg')\n",
    "rgb_path = os.path.join(base_path, 'DogVsMuffin.jpg')\n",
    "face_path = os.path.join(base_path, 'DogVsMuffin_face.jpg')\n",
    "seg_img = imread(seg_path)[80:520:2, :450:2]\n",
    "rgb_img = imread(rgb_path)[80:520:2, :450:2, :]\n",
    "face_img = imread(face_path)\n",
    "print('RGB Size', rgb_img.shape, 'Seg Size',\n",
    "      seg_img.shape, 'Face Size', face_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the baseline ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = seg_img.flatten() > 0\n",
    "score_value = 1-np.mean(rgb_img.astype(np.float32), 2).flatten()/255.0\n",
    "fpr, tpr, _ = roc_curve(ground_truth_labels, score_value)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax1.imshow(rgb_img)  # show the color image\n",
    "ax1.set_title(\"Color Image\")\n",
    "ax2.imshow(seg_img, cmap='gray')  # show the segments\n",
    "ax2.set_title(\"Ground Truth\")\n",
    "ax3.imshow(mark_boundaries(rgb_img, seg_img))\n",
    "ax3.set_title(\"Labeled Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Model\n",
    "We use a library called [Keras](https://keras.io/) which lets us easily build models and avoid making easy mistakes. We focus here on just a single convolutional layers with dimensions 25x25."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "We need to redimnsion the arrays to use them in deep learning libraries. Keras and Tensorflow use the forman BHWC (Batch, Height, Width, Channels) since we just have a single item in our batch we can use `np.expand_dims` to add that dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor = np.expand_dims(rgb_img, 0)/255.0\n",
    "seg_tensor = np.expand_dims(np.expand_dims(seg_img/255.0, -1), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_dim = 25\n",
    "np.random.seed(2019)\n",
    "from functools import reduce\n",
    "def gkern_nd(d=2, kernlen=21, nsigs=3, min_smooth_val=1e-2):\n",
    "    nsigs = [nsigs] * d\n",
    "    k_wid = (kernlen - 1) / 2\n",
    "    all_axs = [np.linspace(-k_wid, k_wid, kernlen)] * d\n",
    "    all_xxs = np.meshgrid(*all_axs)\n",
    "    all_dist = reduce(np.add, [\n",
    "        np.square(cur_xx) / (2 * np.square(np.clip(nsig, min_smooth_val,\n",
    "                                                   kernlen)))\n",
    "        for cur_xx, nsig in zip(all_xxs, nsigs)])\n",
    "    kernel_raw = np.exp(-all_dist)\n",
    "    return kernel_raw / kernel_raw.sum()\n",
    "\n",
    "init_W = np.random.normal(0, 0.005, size=(kernel_dim, kernel_dim, 3, 1))\n",
    "for i in range(np.shape(init_W)[2]):\n",
    "    init_W[:, :, i, 0] += gkern_nd(2, kernel_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 15))\n",
    "plt_kwargs = dict(cmap='RdBu', vmin=-init_W.std()*2, vmax=+init_W.std()*2)\n",
    "bins = np.linspace(plt_kwargs['vmin'], plt_kwargs['vmax'], 20)\n",
    "ax1.matshow(init_W[:, :, 0, 0], **plt_kwargs)\n",
    "ax4.hist(init_W[:, :, 0, 0].ravel(), bins)\n",
    "ax1.set_title('Red Kernel')\n",
    "\n",
    "ax2.matshow(init_W[:, :, 1, 0], **plt_kwargs)\n",
    "ax5.hist(init_W[:, :, 1, 0].ravel(), bins)\n",
    "ax2.set_title('Green Kernel')\n",
    "\n",
    "ax3.matshow(init_W[:, :, 2, 0], **plt_kwargs)\n",
    "ax6.hist(init_W[:, :, 2, 0].ravel(), bins)\n",
    "ax3.set_title('Blue Kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers\n",
    "simple_model = models.Sequential(name='SingleConvLayer')\n",
    "# learn one convolution layer\n",
    "simple_model.add(layers.Conv2D(1, \n",
    "                               kernel_size=(kernel_dim, kernel_dim),\n",
    "                               input_shape = (None, None, 3),\n",
    "                               use_bias=False,\n",
    "                               weights=[init_W],\n",
    "                               activation='sigmoid',\n",
    "                               padding='same'))\n",
    "# the optimizer (how the model is updated)\n",
    "# loss (what is are we trying to minimize)\n",
    "# metrics (how we measure the performance)\n",
    "simple_model.compile(optimizer=optimizers.SGD(lr=1e-2),\n",
    "                     loss='binary_crossentropy',\n",
    "                     metrics=['binary_accuracy', 'mse'])\n",
    "simple_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit(img_tensor,\n",
    "                 seg_tensor,\n",
    "                 epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax1.imshow(rgb_img)  # show the color image\n",
    "ax1.set_title(\"Color Image\")\n",
    "ax2.imshow(seg_img, vmin=0, vmax=1, cmap='viridis')  # show the segments\n",
    "ax2.set_title(\"Ground Truth\")\n",
    "m_output = simple_model.predict(img_tensor)\n",
    "ax3.imshow(m_output[0, :, :, 0], vmin=0, vmax=1, cmap='viridis')\n",
    "ax3.set_title(\"CNN Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = simple_model.fit(img_tensor,\n",
    "                                seg_tensor,\n",
    "                                epochs=10,\n",
    "                                verbose=False)\n",
    "print('Pixel Level Accuracy: {:2.1%}'.format(\n",
    "    loss_history.history['binary_accuracy'][-1]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax1.imshow(rgb_img)  # show the color image\n",
    "ax1.set_title(\"Color Image\")\n",
    "ax2.imshow(seg_img, vmin=0, vmax=1, cmap='viridis')  # show the segments\n",
    "ax2.set_title(\"Ground Truth\")\n",
    "m_output = simple_model.predict(img_tensor)\n",
    "ax3.imshow(m_output[0, :, :, 0], vmin=0, vmax=1, cmap='viridis')\n",
    "ax3.set_title(\"CNN Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_cnn, tpr_cnn, _ = roc_curve(ground_truth_labels, m_output.ravel())\n",
    "roc_auc_cnn = auc(fpr_cnn, tpr_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(fpr, tpr, label='RGB Value (area = %0.2f)' % roc_auc)\n",
    "ax.plot(fpr_cnn, tpr_cnn, label='CNN Output (area = %0.2f)' % roc_auc_cnn)\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver operating characteristic example')\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation\n",
    "We use the augmentation methods covered in the Datasets lecture to increase the amount of data we have and make the model less sennsitive to small changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "idg = ImageDataGenerator(rotation_range=15,\n",
    "                         zoom_range=0.25,\n",
    "                         width_shift_range=0.3,\n",
    "                         height_shift_range=0.3,\n",
    "                         vertical_flip=True,\n",
    "                         horizontal_flip=True)\n",
    "img_gen = idg.flow(img_tensor, seed=1234)\n",
    "seg_gen = idg.flow(seg_tensor, seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model.fit_generator(zip(img_gen, seg_gen), \n",
    "                           steps_per_epoch=20, \n",
    "                           epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 5))\n",
    "ax1.imshow(rgb_img)  # show the color image\n",
    "ax1.set_title(\"Color Image\")\n",
    "ax2.imshow(seg_img, vmin=0, vmax=1, cmap='viridis')  # show the segments\n",
    "ax2.set_title(\"Ground Truth\")\n",
    "m_output = simple_model.predict(img_tensor)\n",
    "ax3.imshow(m_output[0, :, :, 0], vmin=0, vmax=1, cmap='viridis')\n",
    "ax3.set_title(\"CNN Prediction\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_aug, tpr_aug, _ = roc_curve(ground_truth_labels, m_output.ravel())\n",
    "roc_auc_aug = auc(fpr_aug, tpr_aug)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(fpr, tpr, label='RGB Value (area = %0.2f)' % roc_auc)\n",
    "ax.plot(fpr_cnn, tpr_cnn, label='CNN Output (area = %0.2f)' % roc_auc_cnn)\n",
    "ax.plot(fpr_aug, tpr_aug, label='CNN with Augmentation (area = %0.2f)' % roc_auc_aug)\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver operating characteristic example')\n",
    "ax.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What did the model learn?\n",
    "We can look at the exact convolutions the model learned by using the `get_weights` on the layer we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,  = simple_model.layers[0].get_weights()\n",
    "print('Convolution:', W.shape, W.mean(), W.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15, 15))\n",
    "plt_kwargs = dict(cmap='RdBu', vmin=-W.std()*2, vmax=+W.std()*2)\n",
    "bins = np.linspace(plt_kwargs['vmin'], plt_kwargs['vmax'], 20)\n",
    "ax1.matshow(W[:, :, 0, 0], **plt_kwargs)\n",
    "ax4.hist(W[:, :, 0, 0].ravel(), bins)\n",
    "ax1.set_title('Red Kernel')\n",
    "\n",
    "ax2.matshow(W[:, :, 1, 0], **plt_kwargs)\n",
    "ax5.hist(W[:, :, 1, 0].ravel(), bins)\n",
    "ax2.set_title('Green Kernel')\n",
    "\n",
    "ax3.matshow(W[:, :, 2, 0], **plt_kwargs)\n",
    "ax6.hist(W[:, :, 2, 0].ravel(), bins)\n",
    "ax3.set_title('Blue Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "1. How can you improve the neural network model (what can you add, or change)?\n",
    "2. Where might morphological operations fit in?\n",
    "3. What is wrong with our approach for validating the model here? (what data are we using to measure the accuracy)\n",
    "4. What is the loss and how is it being used?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
